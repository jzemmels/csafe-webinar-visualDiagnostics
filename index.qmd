---
title: "Visual Diagnostics for Algorithmic Cartridge Case Comparisons"
author: "Joseph Zemmels, Susan VanderPlas, Heike Hofmann"
title-slide-attributes: 
  data-background-image: images/title-slide-bkgd.png
  data-background-size: contain
bibliography: refs.bib
format: 
  revealjs
---

## Acknowledgements

```{r setup,include=FALSE}
library(x3ptools)
library(tidyverse)
library(rgl)
library(impressions)
library(patchwork)

knitr::opts_chunk$set(fig.align = "center")
```


**Funding statement**

This work was partially funded by the Center for Statistics and Applications in Forensic Evidence (CSAFE) through Cooperative Agreement 70NANB20H019 between NIST and Iowa State University, which includes activities carried out at Carnegie Mellon University, Duke University, University of California Irvine, University of Virginia, West Virginia University, University of Pennsylvania, Swarthmore College and University of Nebraska, Lincoln.

::: {.notes}

Thank you for that introduction and thanks to you all for being here

My name is Joe and I today will discuss some of the research we've done on comparing cartridge case evidence.

If you have any questions, feel free to type them in chat as we go and I will get to them at the end of the presentation.

:::

# Background

::: {.notes}

I'm sure that many of you are already familiar with cartridge case comparisons, but I am going to start off with some background information to make sure that we're all on the same playing field.

:::

## Cartridge Case Comparisons {.smaller}

-   Determine whether two cartridge cases were fired from the same firearm.

```{r,fig.align='center',out.width="35%"}
knitr::include_graphics("images/gunFiringAnimation.gif")
```


- **Cartridge Case**: metal casing containing primer, powder, and projectile

- **Breech Face**: back wall of gun barrel

- **Breech Face Impressions**: markings left on cartridge case surface by the breech face during the firing process

::: {.aside}

GIF source: <https://imgur.com/4CXf9BK>

:::

::: {.notes}

For  this project, we're interested in determining whether two cartridge cases were fired from the same firearm.

A cartridge case is a metal casing containing the primer, powder, and projectile.
In the animation, you can see an example of a cartridge case that is ejected from the barrel after firing

When a gun is fired and the bullet travels down the barrel, the cartridge case stays in the barrel and is sent backwards as a reaction to the bullet moving forward.

It then slams against the back wall of the barrel, also known as the "breech face," with great force.

Markings on the breech face are impressed into surface of the cartridge case, and this leaves so-called "breech face impressions."

Forensic examiners use these breech face impressions analogous to a fingerprint to identify the gun from which a cartridge case was fired.

:::

## Current Practice {.smaller}

- Cartridge cases recovered from crime scene vs. fired from suspect's firearm

- Place evidence under a comparison microscope for simultaneous viewing [@Thompson2017]

- Assess the "agreement" of impressions on the two cartridge cases [@AFTE1992]

![](images/cartridgeCaseZoomIn.png){fig-align="center" width=1000}



::: {.notes}

Suppose that you recover two cartridge cases - one from a crime scene and another is from a suspect's firearm

The way that forensic examinations are commonly performed today involves placing the cartridge cases under a comparison microscope.

An example of a comparison microscope is shown at the bottom of the slide.
The examiner would place the two cartridge cases on stages.
You can see that there are two microscopes, one for each stage, that are combined into a single view that the examiner can look through.

The goal of the forensic examination is to assess the "agreement" of the impressions on the two cartridge cases.
For our purposes, we are particularly interested in the impressions on the cartridge case primer, which you can see higlighted on the left side of the diagram


Current practice says that if you recover two cartridge cases, let's say one is from a crime scene and another is from a suspect's firearm, then you can analyze the markings under a comparison microscope to determine whether they were both fired from the suspect's gun.
The final result is the examiner's conclusion on whether the cartridge cases originated from the same firearm.

:::

## Impression Comparison Algorithms {.smaller}

@nas2009:

*"[T]he decision of a toolmark examiner remains a subjective decision based on unarticulated standards and no statistical foundation for estimation of error rates"*

. . .

@pcast:

*"A second - and more important - direction is (as with latent print analysis) to convert firearms analysis from a subjective method to an objective method. This would involve developing and testing image-analysis algorithms for comparing the similarity of tool marks on bullets [and cartridge cases]."*

. . .

We discuss an image-analysis algorithm to compare 3D topographical images of cartridge cases

  - Visual diagnostics aid in understanding what the algorithm does "under the hood."

::: {.notes}

Now why are we talking about comparison algorithms today?

Well, in recent years the scientific validity of many forensic disciplines has been called into question.

For example in 2009, a report from the National Research Council stated that the decision of a toolmark examiner, which is the examiner who would be looking at these comparisons, remains ... [finish the quote]

Seven years later, the President's Council of Advisors on Science and Technology said something similar and emphasized that firearms analysis should convert from a subjective method to an objective method, which would involve developing image analysis algorithms for comparing the similarity of tool marks on firearm evidence including cartridge cases.

Today, we will discuss an image-analysis algorithm that compares cartridge case evidence.
In particular, we'll introduce a series of diagnostic tools that are useful in understanding how these algorithms work "under the hood."

:::

# Cartridge Case Comparison Algorithms

::: {.notes}

Now that we have the basics down, let's discuss algorithms that compare cartridge cases.

:::

## Ames I Study {.smaller}

- @baldwin collected cartridge cases from 25 Ruger SR9 pistols

. . .

- Separated cartridge cases into quartets: 3 *known-match* + 1 *unknown source*

- *Match* if fired from the same firearm,  *Non-match* if fired from different firearms

. . .

- 216 examiners tasked with determining whether the unknown cartridge case originated from the same pistol as the known-match cartridge cases

- @baldwin interested in the "false positive" and "false negative" error rates of these examiners

  - *False Positive*: Classifying a non-match as a match
  
  - *False Negative*: Classifying a match as a non-match


. . .

- 0.80% overall error rate (26 out of 3,268)

- 1.01% false positive rate (22 out of 2,178 comparisons)

- 0.37% false negative rate (4 out of 1,090 comparisons)

::: {.notes}

Before we dive into algorithms, I wanted to first discuss the data that we will be using throughout this presentation.

We use cartridge cases collected as part of a 2014 study, commonly called the "Ames I" study because it included researchers from Iowa State University.

For the study, the researchers fired cartridge cases from 25 Ruger SR9 pistols

**NEXT**

These cartridge cases were then separated into groups of 4 consisting of 3 "known match" cartridge cases and 1 "unknown source" cartridge case.
It's important to note here that we call cartridge cases a "match" if they were fired from a firearm and "non-match" if they were fired from different firearms.

**NEXT**

The researchers then sent these cartridge case sets to 216 examiners who were tasked with determining whether the one unknown source cartridge case came from the same pistol as the three known-match cartridge cases

The researchers were particularly interested in assessing the false positive and false negative error rates of these examiners
A false positive error occurs when a non-match cartridge case is classified as a match while a false negative error occurs when a matching cartridge case is classified as a non-match

**NEXT**

The results they got back showed that the examiners made very few errors during their examinations.
Out of 3,268 comparisons, examiners only got 26 wrong with a false positive rate of 1.01% and false negative rate of 0.37%.

One goal that we had for this project was to come up with an algorithm that had similar performance to the results of this study


:::


## Cartridge Case Data {.smaller}

- 3D topographic images from Cadre TopMatch scanner [@topmatch]

- **x3p** file contains surface measurements at the micrometer ("micron") level

```{r x3pImage,fig.align='center',fig.width=8,eval=TRUE}
# knitr::knit_hooks$set(webgl = hook_webgl)

K013sA1 <- x3p_read("data/K013sA1.x3p")

K013sA1$mask <- NULL

x3p_image(K013sA1 %>% x3p_sample(m = 4) %>% x3p_rotate(angle = 90),zoom = 1.5)
rglwidget()
```

::: {.notes}

So we have these cartridge cases from the Ames I study, but the question is: "how do we go from a physical cartridge case to something that we can use on a computer?"

The answer is to take a 3D topographical scan of the cartridge case surface using the Cadre TopMatch scanner.
You can see example of one such topographic image on the slide.
This scan is taken at the micrometer, or "micron," level and stored in the x3p file format

This image is actually interactable, so I can show you what the scan looks like from different angles.
Again, we are interested in the cartridge case primer, which is the circular region in the middle of the scan.
You can see that we pick up areas around the primer that we will eventually remove.
You will also note that the firing pin impression is a sort of plateaued region in the middle of the primer that is caused by the deformation of the metal when it's struck by the firing pin.

Keep in mind that we are specifically interested in circular region around this firing pin impression.

:::


## Cartridge Case Comparison Algorithms {.smaller}

Obtain an objective measure of similarity between two cartridge cases

- **Step 1**: Independently *pre-process* scans to isolate breech face impressions

. . .

- **Step 2**: *Compare* two cartridge cases to extract a set of numerical features that distinguish between matches vs. non-matches

. . .

- **Step 3**: Combine numerical features into a single similarity *score* (e.g., predicted probability of a match)

. . .

Examiner takes similarity score into account during an examination

Challenging to know how/when these steps work correctly

::: {.notes}

Now let's discuss comparison algorithms

The goal of a cartridge case comparison algorithm is to obtain a measure of similarity between two cartridge cases

There are different types of algorithms out there right now, but they all follow the same, basic structure

The first step of these algorithms is to pre-process the scans to isolate the breech face impressions.
For example, in the scan we talked about on the last slide, we want to remove the firing pin impression and region around the primer to isolate the breech face impressions.

**NEXT**

Next, once we have two pre-processed cartridge cases, we compare them to extract a set of numerical features that distinguish between matches and non-matches
I'll talk in a few slides about some common numerical features we calculate

**NEXT**

Finally, we combine the numerical features into a single similarity score such as the predicted probability that the two cartridge cases match.

**NEXT**

Eventually, we hope that these algorithms will eventually be used in casework to help the examiner make a conclusion
However, we first need to know an algorithm's limitations before we know *how* the examiner should interpret the similarity score

One challenge we've commonly faced while working with these comparison algorithms is knowing how and when these steps work as we intend them to.
In the next few slides, I will discuss challenges we've faced at each step.

:::

## Step 1: Pre-process

Isolate region in scan that consistently contains breech face impressions

```{r,fig.width=8,fig.align='center',eval=TRUE,include=FALSE}
K013sA1 <- x3p_read("data/K013sA1.x3p") %>%
  x3p_rotate(angle = 180) %>%
  x3p_flip_y() %>%
  sample_x3p(m = 4)

K013sA1$mask <- NULL

K013sA1_processed <- x3p_read("data/K013sA1_processed.x3p") %>%
  x3p_rotate(angle = 180) %>%
  x3p_flip_y() %>%
  x3p_rotate(angle = 90) %>%
  sample_x3p(m = 4)
K013sA1_processed$surface.matrix <- K013sA1_processed$surface.matrix*1e6
K013sA1_processed$header.info$incrementY  <- K013sA1_processed$header.info$incrementY*1e6
K013sA1_processed$header.info$incrementX  <- K013sA1_processed$header.info$incrementX*1e6

K013sA1$surface.matrix <- K013sA1$surface.matrix %>%
  imager::as.cimg() %>%
  imager::pad(nPix = 1,axes = "x",val = 100,pos = -1) %>%
  as.matrix()

K013sA1_processed$surface.matrix <- K013sA1_processed$surface.matrix %>%
  imager::as.cimg() %>%
  imager::pad(nPix = nrow(K013sA1$surface.matrix) - nrow(K013sA1_processed$surface.matrix),
              axes = "x",val = 100) %>%
  imager::pad(nPix = ncol(K013sA1$surface.matrix) - ncol(K013sA1_processed$surface.matrix),
              axes = "y",val = 100) %>%
  as.matrix()

K013sA1_processed$surface.matrix[K013sA1_processed$surface.matrix == 100] <- NA


K013sA1_combined <- K013sA1_processed

K013sA1_combined$surface.matrix <- rbind(K013sA1$surface.matrix,matrix(NA,ncol = ncol(K013sA1$surface.matrix),nrow = 10),K013sA1_processed$surface.matrix)
```

```{r,fig.width=8,fig.align='center',eval=TRUE,include=TRUE}
x3p_image(K013sA1_combined,zoom=1)

# x3p_snapshot(file = "figures/preProcess_x3pImage.png")
# knitr::plot_crop("figures/preProcess_x3pImage.png")
# rgl::close3d()

rglwidget()
```


# ```{r,out.width="100%",include=TRUE,eval=TRUE}
# knitr::include_graphics("figures/preProcess_x3pImage.png")
# ```


```{r preProcessExample,fig.align='center',eval=FALSE}
if(!file.exists("figures/preProcessExample.png")){
  K013sA1 <- x3p_read("data/K013sA1.x3p") %>%
    x3p_rotate(angle = 180) %>%
    x3p_flip_y()
  
  K013sA1_processed <- x3p_read("data/K013sA1_processed.x3p")
  K013sA1_processed$surface.matrix <- K013sA1_processed$surface.matrix*1e6
  
  plt1 <- impressions::x3pPlot(K013sA1,
                               x3pNames = c("K013sA1"),
                               legend.quantiles = c(0,.1,.5,.9,1))
  
  plt2 <- impressions::x3pPlot(K013sA1_processed,
                               x3pNames = c("K013sA1 Pre-processed"),
                               legend.quantiles = c(0,.1,.5,.9,1))
  
  plt <- (plt1 | plt2)
  
  ggsave(plot = plt,filename = "figures/preProcessExample.png",width = 10,height = 5)
  knitr::plot_crop("figures/preProcessExample.png")
}
```

```{r,out.width="100%",include=TRUE,eval=FALSE}
knitr::include_graphics("figures/preProcessExample.png")
```

. . .

***How do we know when a scan is adequately pre-processed?***

## Step 2: Compare Full Scans {.smaller}

- *Registration*: Determine rotation and translation to align two scans


```{r fullScanComparison}
K013sA2_processed <- x3p_read("data/K013sA2_processed.x3p")

if(!file.exists("data/fullScan_knownMatch.rds")){
  fullScan_knownMatch <- scored::comparison_fullScan(reference = K013sA1_processed,
                                          target = K013sA2_processed,
                                          returnX3Ps = FALSE) %>%
    group_by(direction) %>%
    filter(fft_ccf == max(fft_ccf)) %>%
    ungroup() %>%
    select(direction,theta) %>%
    pmap_dfr(~ {
      
      scored::comparison_fullScan(reference = K013sA1_processed,
                                  target = K013sA2_processed,
                                  thetas = ..2,
                                  returnX3Ps = TRUE) %>%
        filter(direction == ..1)
      
    })
  
  saveRDS(fullScan_knownMatch,"data/fullScan_knownMatch.rds")
}
```

```{r,fig.align='center',out.width="75%"}
knitr::include_graphics("images/fullScanRegistrationDiagram.png")
```

. . .

- *Cross-correlation function* (CCF) measures similarity between scans

  - Choose the rotation/translation that maximizes the CCF

## Step 2: Compare Cells {.smaller}

- Split one scan into a grid of cells that are each registered to the other scan

- For a matching pair, we assume that cells will agree on the same rotation & translation

```{r}
if(!file.exists("data/cellBased_knownMatch.rds")){
  cellBased_knownMatch <- bind_rows(scored::comparison_cellBased(reference = K013sA1_processed,
                                                     target = K013sA2_processed,
                                                     thetas = 3,
                                                     numCells = c(4,4),
                                                     direction = "one",
                                                     returnX3Ps = TRUE) %>%
                          mutate(direction = "reference_vs_target"),
                        scored::comparison_cellBased(reference = K013sA2_processed,
                                                     target = K013sA1_processed,
                                                     thetas = -3,
                                                     numCells = c(4,4),
                                                     direction = "one",
                                                     returnX3Ps = TRUE) %>%
                          mutate(direction = "target_vs_reference"))
  
  saveRDS(cellBased_knownMatch,"data/cellBased_knownMatch.rds")
}
```

```{r,fig.align='center',out.width="75%"}
knitr::include_graphics("images/cellBasedRegistrationDiagram.png")
```

. . .

***Why does the algorithm "choose" a particular registration?***

::: {.notes}

We essentially repeat the process from the last slide with each cell

:::

## Step 3: Score {.smaller}

- Measure of similarity for two cartridge cases

  - Maximized CCF (0.27 in example below) [@vorburger_surface_2007; @tai_fully_2018]

  - Congruent Matching Cells (11 CMCs in example below) [@song_proposed_2013]
  
```{r}
if(!file.exists("figures/cmcPlot_knownMatch.png")){
  
  K013sA1_processed <- x3p_read("data/K013sA1_processed.x3p")
  K013sA2_processed <- x3p_read("data/K013sA2_processed.x3p")
  
  cellBasedComparison_8x8 <- scored::comparison_cellBased(reference = K013sA1_processed,
                                                          target = K013sA2_processed,
                                                          direction = "both",
                                                          numCells = c(8,8),
                                                          returnX3Ps = FALSE)
  
  
  cmcClassifs <- cellBasedComparison_8x8 %>%
    group_by(direction) %>%
    mutate(originalMethod = cmcR::decision_CMC(cellIndex=cellIndex,
                                               x=x,
                                               y=y,
                                               theta=theta,
                                               corr=pairwiseCompCor))
  
  cmcs <- cmcClassifs %>%
    filter(originalMethod == "CMC") %>%
    filter(direction == "reference_vs_target" & originalMethod == "CMC") %>%
    ungroup() %>%
    select(cellIndex,theta,originalMethod)
  
  non_cmcs <- cmcClassifs %>%
    filter(direction == "reference_vs_target") %>%
    group_by(cellIndex) %>%
    filter(fft_ccf == max(fft_ccf)) %>%
    ungroup() %>%
    select(cellIndex,theta,originalMethod) %>%
    anti_join(cmcs,by = "cellIndex")
  
  alignedCells <- bind_rows(cmcs,non_cmcs) %>%
    group_by(theta) %>%
    group_split() %>%
    map_dfr(function(dat){
      
      scored::comparison_cellBased(reference = K013sA1_processed,
                                   target = K013sA2_processed,
                                   direction = "one",
                                   numCells = c(8,8),
                                   thetas = unique(dat$theta),
                                   returnX3Ps = TRUE) %>%
        filter(cellIndex %in% dat$cellIndex) %>%
        left_join(dat %>% select(cellIndex,originalMethod),
                  by = "cellIndex")
      
    })
  
  saveRDS(alignedCells,file = "data/cellBased_knownMatch_8x8.rds")
  
  cmcPlot_knownMatch <- cmcR::cmcPlot(reference = K013sA1_processed,
                                      target = K013sA2_processed,
                                      cmcClassifs = alignedCells)
  
  ggsave(filename = "figures/cmcPlot_knownMatch.png",plot = cmcPlot_knownMatch,height = 5,width = 10)
  knitr::plot_crop("figures/cmcPlot_knownMatch.png")
  
}
```


```{r,include=TRUE}
knitr::include_graphics("figures/cmcPlot_knownMatch.png")
```

. . .

- **Our approach**: predicted probability of a match using a statistical model

***What factors influence the final similarity score?***

# Visual Diagnostics

## Visual Diagnostics for Algorithms {.smaller}

- A number of questions arise out of using comparison algorithms

  - *How do we know when a scan is adequately pre-processed?*

  - *Why does the algorithm "choose" a particular registration?*

  - *What factors influence the final similarity score?*


. . .

- We wanted to create tools that are useful for answering these questions

  - Well-constructed visuals are intuitive and powerful


## X3P Plot {.smaller}

- Map quantiles of surface values to a divergent color scheme

```{r,include=TRUE,width = "60%"}
knitr::include_graphics("images/x3pPlot_colorscheme.png")
```

- Emphasizes extreme values in scan that may need to be removed during pre-processing

- Allows for comparison of multiple scans on the same color scheme

```{r x3pPlot-comparison}
if(!file.exists("figures/x3pPlot_comparison.png")){
  
  K013sA1_processed <- x3p_read("data/K013sA1_processed.x3p")
  K013sA1_processed$surface.matrix <- K013sA1_processed$surface.matrix*1e6
  K013sA2_processed <- x3p_read("data/K013sA2_processed.x3p")
  K013sA2_processed$surface.matrix <- K013sA2_processed$surface.matrix*1e6
  
  plt <- x3pPlot(K013sA1_processed,K013sA2_processed,x3pNames = c("K013sA1","K013sA2"),legend.quantiles = c(0,.01,.1,.5,.9,.99,1))
  
  ggsave(filename = "figures/x3pPlot_comparison.png",plot=plt,width=10,height = 5)
  knitr::plot_crop("figures/x3pPlot_comparison.png")
  
}
```

```{r,include=TRUE,out.width="65%"}
knitr::include_graphics("figures/x3pPlot_comparison.png")
```

## X3P Plot Pre-processing Example {.smaller}

Useful for diagnosing when scans need additional pre-processing

```{r,include=TRUE,fig.align='center',out.width = "100%"}
knitr::include_graphics("images/preProcessEffectExample.png")
```

## Comparison Plot {.smaller .scrollable}

- Separate aligned scans into similarities and differences

- Useful for understanding a registration

. . .

- *Similarities*: Element-wise average between two scans after filtering elements that are less than 1 micron apart
  
- *Differences*: Elements of both scans that are at least 1 micron apart

```{r eval=FALSE}
fullScan_knownMatch <- readRDS("data/fullScan_knownMatch.rds")

reference <- fullScan_knownMatch$cellHeightValues[[1]]
reference$surface.matrix <- reference$surface.matrix*reference$cmcR.info$scaleByVal*1e6

target <- fullScan_knownMatch$alignedTargetCell[[1]]
target$surface.matrix <- target$surface.matrix*target$cmcR.info$scaleByVal*1e6

x3pPlot(impressions::x3p_elemAverage(reference,target),
        x3pNames = "Element-wise Average")

x3pDiff <- reference
x3pDiff$surface.matrix <- abs(reference$surface.matrix - target$surface.matrix)

surfaceMat_df <- purrr::pmap_dfr(.l = list(list(x3pDiff),
                                               "Element-wise Distance"),
                                     function(x3p,name){

                                       x3p$header.info$incrementX <- 1
                                       x3p$header.info$incrementY <- 1
                                       x3p$mask <- NULL

                                       x3p %>%
                                         x3ptools::x3p_to_df() %>%
                                         dplyr::mutate(xnew = max(.data$y) - .data$y,
                                                       ynew = max(.data$x) - .data$x) %>%
                                         dplyr::select(-c(.data$x,.data$y)) %>%
                                         dplyr::rename(x=.data$xnew,
                                                       y=.data$ynew) %>%
                                         dplyr::mutate(x3p = rep(name,times = nrow(.)))
                                     })

surfaceMat_df %>%
      ggplot2::ggplot(ggplot2::aes(x = .data$x,y = .data$y)) +
      ggplot2::geom_raster(ggplot2::aes(fill = .data$value))  +
      ggplot2::scale_fill_gradientn(colours =  c('#2d004b','#542788','#8073ac','#b2abd2','#d8daeb','#f7f7f7','#fee0b6','#fdb863','#e08214','#b35806','#7f3b08'),
                                    values = scales::rescale(quantile(surfaceMat_df$value,
                                                                      c(0,.01,.025,.1,.25,.5,.75,0.9,.975,.99,1),
                                                                      na.rm = TRUE)),
                                    breaks = function(lims){
                                      dat <- quantile(surfaceMat_df$value,c(0,.75,.99,1),na.rm = TRUE)

                                      dat <- dat %>%
                                        setNames(paste0(names(dat)," [",round(dat,3),"]"))

                                      return(dat)
                                    },
                                    na.value = "gray65") +
      ggplot2::coord_fixed(expand = FALSE) +
      ggplot2::theme_minimal() +
      ggplot2::theme(
        axis.title.x = ggplot2::element_blank(),
        axis.text.x = ggplot2::element_blank(),
        axis.ticks.x = ggplot2::element_blank(),
        axis.title.y = ggplot2::element_blank(),
        axis.text.y = ggplot2::element_blank(),
        axis.ticks.y = ggplot2::element_blank(),
        panel.grid.major = ggplot2::element_blank(),
        panel.grid.minor = ggplot2::element_blank(),
        panel.background = ggplot2::element_blank()) +
      ggplot2::guides(fill = ggplot2::guide_colourbar(barheight = grid::unit(3,"in"),
                                                      label.theme = ggplot2::element_text(size = 8),
                                                      title.theme = ggplot2::element_text(size = 10),
                                                      frame.colour = "black",
                                                      ticks.colour = "black"),
                      colour = 'none') +
      ggplot2::labs(fill = expression("Rel. Height ["*mu*"m]")) +
      ggplot2::facet_wrap(~ x3p)


x3pDiff_bin <- x3pDiff
x3pDiff_bin$surface.matrix <- (x3pDiff_bin$surface.matrix > 1)

x3pDiff_bin %>%
  x3ptools::x3p_to_df() %>%
  mutate(x = x/x3pDiff_bin$header.info$incrementX,
         y = y/x3pDiff_bin$header.info$incrementY) %>%
  dplyr::mutate(xnew = max(.data$y) - .data$y,
                                                       ynew = max(.data$x) - .data$x) %>%
                                         dplyr::select(-c(.data$x,.data$y)) %>%
                                         dplyr::rename(x=.data$xnew,
                                                       y=.data$ynew) %>%
  ggplot(aes(x=x,y=y)) +
  geom_raster(fill = "gray65") +
  geom_raster(aes(fill=value)) +
  coord_fixed(expand=FALSE) +
  theme_void() +
  scale_fill_manual(values = c("black","white"),
                    na.value = "gray65",
                    na.translate = FALSE) +
  theme(legend.key = element_rect(color = "black")) +
  labs(fill = "Greater than 1")

x3pAveraged_filt <- x3p_filter(x3p = x3p_elemAverage(reference,target),
                               cond = function(x,y,thresh) abs(y) <= thresh,
                               y = c({reference$surface.matrix - target$surface.matrix}),
                               thresh = 1)

```


![](images/filteringIllustration.png){fig-align="center"}

## Full Scan Comparison Plot

```{r}
if(!file.exists("figures/comparisonPlotExample.png")){
  
  fullScan_knownMatch <- readRDS("data/fullScan_knownMatch.rds")
  refAligned <- fullScan_knownMatch$cellHeightValues[[1]]
  refAligned$surface.matrix <- refAligned$surface.matrix*refAligned$cmcR.info$scaleByVal*1e6
  targAligned <- fullScan_knownMatch$alignedTargetCell[[1]]
  targAligned$surface.matrix <- targAligned$surface.matrix*targAligned$cmcR.info$scaleByVal*1e6
  
  plt <- impressions::x3p_comparisonPlot(x3p1 = refAligned,x3p2 = targAligned,
                                         plotLabels = c("K013sA1","K013sA2 Aligned",
                                                        "Element-wise Average",
                                                        "K013sA1 Differences","K013sA2 Differences"),
                                         legendLength = 20,
                                         legendUnit = "micron",
                                         legendQuantiles = c(0,.01,.5,.99,1))
  
  ggsave(filename = "figures/comparisonPlotExample.png",plot = plt,width = 10,height = 6,bg = "white")
  knitr::plot_crop("figures/comparisonPlotExample.png")
  
}
```

```{r,include=TRUE,out.width = "100%"}
knitr::include_graphics("figures/comparisonPlotExample.png")
```

## Cell Comparison Plot

<!-- ::: {.fragment .fade-up fragment-index=1} -->

<!-- ![](images/cellBasedRegistration_cell1-6.png){.absolute top=0 right=30 width=200 height=100} -->

<!-- ::: -->

```{r}
if(!file.exists("figures/cellBasedComparison.png")){
 
  cellBased_knownMatch <- readRDS("data/cellBased_knownMatch.rds")
  
  plt <- cellBased_knownMatch %>%
    filter(direction == "reference_vs_target") %>%
    filter(cellIndex == "1, 6") %>%
    select(cellIndex,cellHeightValues,alignedTargetCell) %>%
    pmap(~ {
      
      x3p1 <- ..2
      x3p2 <- ..3
      
      x3p1$surface.matrix <- x3p1$surface.matrix*x3p1$cmcR.info$scaleByVal*1e6
      x3p2$surface.matrix <- x3p2$surface.matrix*x3p2$cmcR.info$scaleByVal*1e6
      
      impressions::x3p_comparisonPlot(x3p1,x3p2,
                                      plotLabels = c(paste0("K013sA1 Cell ",..1),
                                                     paste0("K013sA2 Aligned Cell"),
                                                     "Element-wise Average",
                                                     paste0("K013sA1 Cell ",..1," Differences"),
                                                     paste0("K013sA2 Aligned Cell\nDifferences")),
                                      label_y = 45,
                                      legendUnit = "micron")
      
    })
  
  ggsave(filename = "figures/cellBasedComparison.png",plot = plt[[1]],
         width = 10,height = 6,bg = "white")
  knitr::plot_crop("figures/cellBasedComparison.png")
  
}
```

<div class="r-stack">

::: {.fragment fade-out fragment-index=1}

![](images/cellBasedRegistration_cell1-6.png){fig-align="center" width=100%}

:::

::: {.fragment .fade-up fragment-index=1}

```{r,include=TRUE,out.width = "100%"}
knitr::include_graphics("figures/cellBasedComparison.png")
```

:::

</div>

## Translating Visuals to Statistics {.smaller}

- Quantify what our intuition says should be true for (non-)matching scans

<!-- ```{r,include=TRUE,out.width = "50%"} -->
<!-- knitr::include_graphics("figures/cellBasedComparison.png") -->
<!-- ``` -->

. . .

- For a matching cartridge case pair...

  1. There should be more similarities than differences
  
  2. The different regions should be relatively small 

  3. The surface values of the different regions should follow similar trends

## Similarities vs. Differences Ratio {.smaller .scrollable}
  
```{r,eval = FALSE,include=FALSE}
cellBased_knownMatch <- readRDS("data/cellBased_knownMatch.rds")

cell16 <- cellBased_knownMatch %>%
  filter(cellIndex == "1, 6" & direction == "reference_vs_target")

cell16_reference <- cell16$cellHeightValues[[1]]
cell16_target <- cell16$alignedTargetCell[[1]]

cell16_reference$surface.matrix <- cell16_reference$surface.matrix*cell16_reference$cmcR.info$scaleByVal*1e6
cell16_target$surface.matrix <- cell16_target$surface.matrix*cell16_target$cmcR.info$scaleByVal*1e6

x3pAveraged <- x3p_filter(x3p = x3p_elemAverage(cell16_reference,cell16_target),
                            cond = function(x,y,thresh) abs(y) <= thresh,
                            y = c({cell16_reference$surface.matrix - cell16_target$surface.matrix}),
                            thresh = 1)

x3pAveraged_differences <- x3p_filter(x3p = x3p_elemAverage(cell16_reference,cell16_target),
                            cond = function(x,y,thresh) abs(y) > thresh,
                            y = c({cell16_reference$surface.matrix - cell16_target$surface.matrix}),
                            thresh = 1)

x3pPlot(x3pAveraged,x3pAveraged_differences)
```


```{r,eval=FALSE}
cellBased_knownMatch <- readRDS("data/cellBased_knownMatch.rds")

cell16 <- cellBased_knownMatch %>%
  filter(cellIndex == "1, 6" & direction == "reference_vs_target")

cell16_reference <- cell16$cellHeightValues[[1]]
cell16_target <- cell16$alignedTargetCell[[1]]

cell16_reference$surface.matrix <- cell16_reference$surface.matrix*cell16_reference$cmcR.info$scaleByVal*1e6
cell16_target$surface.matrix <- cell16_target$surface.matrix*cell16_target$cmcR.info$scaleByVal*1e6

x3pAveraged_differences <- x3p_filter(x3p = x3p_elemAverage(cell16_reference,cell16_target),
                            cond = function(x,y,thresh) abs(y) > thresh,
                            y = c({cell16_reference$surface.matrix - cell16_target$surface.matrix}),
                            thresh = 1)

x3pAveraged_binarized <- x3pAveraged_differences
x3pAveraged_binarized$surface.matrix <- !is.na(x3pAveraged_binarized$surface.matrix)

imager::label(imager::as.cimg(x3pAveraged_binarized$surface.matrix)) %>%
  as.data.frame() %>%
  filter(value > 0) %>%
  group_by(value) %>%
  tally() %>%
  mutate(n = n*x3pAveraged_binarized$header.info$incrementY*1e6) %>%
  summarize(meanSize = mean(n),
            sdSize = sd(n))

imager::label(imager::as.cimg(x3pAveraged_binarized$surface.matrix)) %>%
  as.data.frame() %>%
  filter(value > 0) %>%
  group_by(value) %>%
  tally() %>%
  mutate(n = n*x3pAveraged_binarized$header.info$incrementY*1e6) %>%
  ggplot(aes(x = n)) +
  geom_histogram(fill = "grey50",colour = "black",
                 binwidth =  7.37364) +
  theme_bw() +
  scale_y_continuous(breaks = 1:9,limits = c(0,6.2)) +
  coord_cartesian(expand = FALSE,xlim = c(0,350)) +
  labs(x = expression(Region~Size~'('~micron^2~')'),
       y = "Number of regions") +
  theme(axis.title = element_text(size = 12),
        axis.text = element_text(size = 11))
```


```{r,eval=FALSE}
cellBased_knownMatch <- readRDS("data/cellBased_knownMatch.rds")

cell16 <- cellBased_knownMatch %>%
  filter(cellIndex == "1, 6" & direction == "reference_vs_target")

cell16_reference <- cell16$cellHeightValues[[1]]
cell16_target <- cell16$alignedTargetCell[[1]]

cell16_reference$surface.matrix <- cell16_reference$surface.matrix*cell16_reference$cmcR.info$scaleByVal*1e6
cell16_target$surface.matrix <- cell16_target$surface.matrix*cell16_target$cmcR.info$scaleByVal*1e6

x3pAveraged_differences <- x3p_filter(x3p = x3p_elemAverage(cell16_reference,cell16_target),
                            cond = function(x,y,thresh) abs(y) > thresh,
                            y = c({cell16_reference$surface.matrix - cell16_target$surface.matrix}),
                            thresh = 1)

cell16_reference_differences <- x3p_filter(x3p = cell16_reference,
                            cond = function(x,y,thresh) abs(y) > thresh,
                            y = c({cell16_reference$surface.matrix - cell16_target$surface.matrix}),
                            thresh = 1)

cell16_target_differences <- x3p_filter(x3p = cell16_target,
                            cond = function(x,y,thresh) abs(y) > thresh,
                            y = c({cell16_reference$surface.matrix - cell16_target$surface.matrix}),
                            thresh = 1)

x3pPlot(cell16_reference_differences,cell16_target_differences)

cor(c(cell16_reference_differences$surface.matrix),
    c(cell16_target_differences$surface.matrix),use = "pairwise.complete.obs")
```

1. There should be more similarities than differences

> *Ratio between number of similar vs. different observations*

![](images/filteredRatioDiagram.png){width="10%" fig-align="center"}



## Different Region Size {.smaller  .scrollable}

2. The different regions should be relatively small 

> *Size of the different regions*

![](images/neighborhoodSizeExample.png){width=1000 fig-align="center"}

## Different Region Correlation {.smaller  .scrollable}

3. The surface values of the different regions should follow similar trends

> *Correlation between the different regions of the two scans*

![](images/differenceCorrelationExample.png){width="50%" fig-align="center"}

## Statistics vs. Similarity Scores

- Useful for predicting the score returned by a comparison algorithm

[Figure showing feature value vs. class probability]

# Automatic Cartridge Evidence Scoring (ACES) Algorithm

## Automatic Cartridge Evidence Scoring {.smaller}

![](images/ACES_pipelineDiagram.png){fig-align="center" width=1000}

- Comparison algorithm that pre-processes, compares, and scores two cartridge case scans

. . .

- Computes 19 numerical features for each cartridge case pair

. . .

- Predicts match probability for an unknown cartridge case pair using trained statistical model

## Visual Diagnostic Features {.smaller .scrollable}

- Use visual diagnostic statistics discussed earlier as numerical features

. . .

- Features:

  - From the full scan comparison:

    - Similarities vs. differences ratio
    
    - Average and standard deviation of different region sizes
    
    - Different region correlation
    
  - From cell-based comparison:
  
    - Average and standard deviation of similarities vs. differences ratios
    
    - Average and standard deviation of different region sizes
    
    - Average different region correlation

[Feature densities here]

## Registration-based Features {.smaller .scrollable}

- For a matching cartridge case pair...

  - Correlation should be large at the full scan *and* cell levels
  
  - Cells should "agree" on a particular registration

. . .

- Compute summary statistics of full-scan and cell-based registration results

- Features:

  - Correlation from full scan comparison
  
  - Mean and standard deviation of correlations from cell comparisons
  
  - Standard deviation of cell-based registration values (horizontal/vertical translations & rotation)

[Feature density plot here]

## Density-based Features {.smaller .scrollable}

- For a matching cartridge case pair...

  - Cells should "agree" on a particular registration
  
  - The estimated registrations between the two comparison directions should be opposites

. . .

- Apply Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm to the cell-based registration results [@dbscan;@zhang_convergence_2021]

```{r eval=FALSE}
K013sA1_processed <- x3p_read("data/K013sA1_processed.x3p")
K013sA2_processed <- x3p_read("data/K013sA2_processed.x3p")

refVsTarget_8x8 <- scored::comparison_cellBased(reference = K013sA1_processed,
                                                target = K013sA2_processed,
                                                direction = "one",
                                                numCells = c(8,8),
                                                thetas = 3,
                                                returnX3Ps = TRUE)

cmcPlot_refVsTarget <- cmcR::cmcPlot(reference = K013sA1_processed,
                                    target = K013sA2_processed,
                                    cmcClassifs = refVsTarget_8x8  %>%
                                      mutate(clust = scored::densityBasedClusters(x=x,
                                                                                  y=y,
                                                                                  eps=4,
                                                                                  minPts=5),
                                             originalMethod = ifelse(clust > 0,"CMC","Non-CMC")),
                                    type = "list")

targetVsRef_8x8 <- scored::comparison_cellBased(reference = K013sA2_processed,
                                                target = K013sA1_processed,
                                                direction = "one",
                                                numCells = c(8,8),
                                                thetas = -3,
                                                returnX3Ps = TRUE)

cmcPlot_targetVsRef <- cmcR::cmcPlot(reference = K013sA2_processed,
                                    target = K013sA1_processed,
                                    cmcClassifs = targetVsRef_8x8 %>%
                                      mutate(clust = scored::densityBasedClusters(x=x,
                                                                                  y=y,
                                                                                  eps=4,
                                                                                  minPts=5),
                                             originalMethod = ifelse(clust > 0,"CMC","Non-CMC")),
                                    type = "list")

cmcPlot_refVsTarget$target +
  theme(strip.text = element_blank()) +
  annotate(geom = "text",x = 230,y = 190,label = "K013sA2",size = 6)

cmcPlot_targetVsRef$target +
  theme(strip.text = element_blank()) +
  annotate(geom = "text",x = 230,y = 190,label = "K013sA1",size = 6)

refVsTarget_8x8 %>%
  mutate(direction = "K013sA2 Aligned Cell Translations, Rotation: 3 degrees") %>%
  select(cellIndex,direction,x,y) %>%
  group_by(direction) %>%
  mutate(clust = factor(scored::densityBasedClusters(x=x,
                                                 y=y,
                                                 eps=4,
                                                 minPts=5),
                        labels = c("Noise","Cluster")))%>%
  mutate(x = x*K013sA1_processed$header.info$incrementX*1e6,
         y = y*K013sA1_processed$header.info$incrementX*1e6) %>%
  # summarize(x = max(abs(x)),y = max(abs(y)))
  ggplot(aes(x=x,y=y,colour = clust)) +
  # geom_point(size = 2) +
  geom_jitter(size = 2,width = 10,height = 10,
              alpha = .5) +
  theme_bw() +
  coord_fixed() +
  theme(legend.position = "none") +
  scale_color_manual(values = c("red","blue")) +
  labs(colour = "DBSCAN Result",
       x = "horizontal shift (micron)",
       y = "vertical shift (micron)") +
  facet_wrap(~direction,nrow = 1) +
  scale_x_continuous(limits = c(-530,530),
                     breaks = scales::pretty_breaks()) +
  scale_y_continuous(limits = c(-530,530),
                     breaks = scales::pretty_breaks()) +
  geom_hline(yintercept = 0,linetype = "dashed") +
  geom_vline(xintercept = 0,linetype = "dashed")

targetVsRef_8x8 %>%
  mutate(direction = "K013sA1 Aligned Cell Translations, Rotation: -3 degrees") %>%
  select(cellIndex,direction,x,y) %>%
  mutate(clust = factor(scored::densityBasedClusters(x=x,
                                                 y=y,
                                                 eps=4,
                                                 minPts=5),
                        labels = c("Noise","Cluster")))%>%
  mutate(x = x*K013sA1_processed$header.info$incrementX*1e6,
         y = y*K013sA1_processed$header.info$incrementX*1e6) %>%
  # summarize(x = max(abs(x)),y = max(abs(y)))
  ggplot(aes(x=x,y=y,colour = clust)) +
  geom_jitter(size = 2,width = 10,height = 10,
              alpha = .5) +
  theme_bw() +
  coord_fixed() +
  theme(legend.position = "none") +
  scale_color_manual(values = c("red","blue")) +
  labs(colour = "DBSCAN Result",
       x = "reversed horizontal shift (micron)",
       y = "reversed vertical shift (micron)") +
  facet_wrap(~direction,nrow = 1) +
  scale_x_reverse(limits = c(530,-530),
                     breaks = scales::pretty_breaks()) +
  scale_y_reverse(limits = c(530,-530),
                     breaks = scales::pretty_breaks()) +
  geom_hline(yintercept = 0,linetype = "dashed") +
  geom_vline(xintercept = 0,linetype = "dashed")
```

![](images/densityBasedFeatureExample.png){fig-align="center" width=700}

. . .

- Features: 

  - Average cluster size

  - DBSCAN cluster indicator

  - Absolute sum of density-estimated rotations

  - Root sum of squares of the cluster-estimated translations

## ACES Statistical Model {.smaller}

- Compute 19 features for each pairwise comparison

- Use 510 cartridge cases collected by @baldwin to fit a *logistic regression* classifier model

. . .

- Train logistic regression model using 21,945 pairwise comparisons from 210 scans

  - Classify each pair as a "match" or "non-match" based on estimated match probability
  
  - Select model that minimizes overall error rate while balancing false positive & false negative rates

. . .

- Test model on 44,850 pairwise comparisons from 300 scans

  - Compute false positive and false negative rates
  
  - Consider distributions of match probabilities for truly matching and non-matching pairs


## Cartridge Case Classification Results {.smaller}

| Source | False Positive (%) | False Negative (%) | Overall Error (%) |
| ------ | -------------: | -------------: | -----------: |
| @baldwin | 1.01 | 0.37 | 0.80 |
| ACES, Balanced FP/FN | 1.82 | 1.82 | 1.82 |
<!-- | ACES, Optim. Accu0.9818191racy | 0.06 | 3.68 | 0.42 | -->

- *ACES False Positive*: 359 out of 19,746 non-match comparisons

- *ACES False Negative*: 40 out of 2,199 match comparisons

. . .

Notes:

- We compare every *pair*wise comparison (1 to 1), @baldwin compared quartets (3 to 1)

- We consider classification accuracy as a means of selecting/comparing models. In practice, the examiner would use the estimated match probability as part of their examination.

## Match Probability Distributions

[Plot of match probabilities for test data]

# Conclusions

## Conclusions & Future Work {.smaller}

- Automatic comparison algorithms are useful for obtaining numerical measures of similarity for two pieces of evidence

- Visual diagnostics help explain what happens "under the hood" of comparison algorithms

. . .

- Our visual diagnostic tools aid in understanding each step of a cartridge case comparison algorithm

  - Also useful by themselves to visually compare cartridge case evidence

- The Automatic Cartridge Evidence Scoring (ACES) algorithm shows promise at measuring the similarity between cartridge cases

. . .

- Need additional "stress tests" (different ammunition/firearms, degradation levels, etc.)

- Explore other optimization criteria than balancing FP and FN error rates

## Software

- **impressions** R package for visual diagnostics
  - <https://jzemmels.github.io/impressions/>

- **scored** R package for ACES algorithm
  - <https://jzemmels.github.io/scored/>

- **cartridgeInvestigatR** interactive web application
  - <https://csafe.shinyapps.io/cartridgeInvestigatR/>

## References

::: {#refs}

:::
